{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0\n",
      "9.0\n",
      "15.0\n",
      "21.0\n",
      "27.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "sess=tf.Session()\n",
    "x_vals=np.array([1.,3.,5.,7.,9.])\n",
    "x_data=tf.placeholder(tf.float32)\n",
    "m_const=tf.constant(3.)\n",
    "my_product=tf.multiply(x_data,m_const)\n",
    "for x_val in x_vals:\n",
    "    print(sess.run(my_product,feed_dict={x_data:x_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "my_array = np.array([[1., 3., 5., 7., 9.],\n",
    "                          [-2., 0., 2., 4., 6.],\n",
    "                          [-6., -3., 0., 3., 6.]])\n",
    "x_vals=np.array([my_array,my_array+1])\n",
    "x_data=tf.placeholder(tf.float32,shape=(3,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1=tf.constant([[1.],[0.],[-1.],[2.],[4.]])\n",
    "m2=tf.constant([[2.]])\n",
    "a1=tf.constant([[10.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "prod1=tf.matmul(x_data,m1)\n",
    "prod2=tf.matmul(prod1,m2)\n",
    "add1=tf.add(prod2,a1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 102.]\n",
      " [  66.]\n",
      " [  58.]]\n",
      "[[ 114.]\n",
      " [  78.]\n",
      " [  70.]]\n"
     ]
    }
   ],
   "source": [
    "for x_val in x_vals:\n",
    "    print(sess.run(add1,feed_dict={x_data:x_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_shape=[1,4,4,1]\n",
    "x_val=np.random.uniform(size=x_shape)\n",
    "x_data=tf.placeholder(tf.float32,shape=x_shape)\n",
    "my_filter=tf.constant(0.25,shape=[2,2,1,1])\n",
    "my_strides=[1,2,2,1]\n",
    "mov_avg_layer=tf.nn.conv2d(x_data,my_filter,my_strides,padding='SAME',name='Moving_Avg_Window')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def custom_layer(input_matrix):\n",
    "    input_matrix_sqeezed=tf.squeeze(input_matrix)\n",
    "    A=tf.constant([[1.,2.],[-1.,3.]])\n",
    "    b=tf.constant(1.,shape=[2,2])\n",
    "    temp1=tf.matmul(A,input_matrix_sqeezed)\n",
    "    temp=tf.add(temp1,b)\n",
    "    return(tf.sigmoid(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('Custom_Layer') as scope:\n",
    "    custom_layer1=custom_layer(mov_avg_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.871427    0.91368991]\n",
      " [ 0.72265363  0.8423382 ]]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(custom_layer1,feed_dict={x_data: x_val}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x_vals = tf.linspace(-1.,1.,500)\n",
    "target = tf.constant(0.)\n",
    "l2_y_vals=tf.square(target - x_vals)\n",
    "l2_y_out=sess.run(l2_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "l1_y_vals = tf.abs(target - x_vals)\n",
    "l1_y_out = sess.run(l1_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta1 = tf.constant(0.25)\n",
    "phuber1_y_vals = tf.multiply(tf.square(delta1), tf.sqrt(1. + tf.square((target - x_vals)/delta1))-1.)\n",
    "phuber1_y_out = sess.run(phuber1_y_vals)\n",
    "delta2 = tf.constant(5.)\n",
    "phuber2_y_vals = tf.multiply(tf.square(delta2),tf.sqrt(1. + tf.square((target-x_vals)/delta2))-1.)\n",
    "phuber2_y_out = sess.run(phuber2_y_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_vals = tf.linspace(-3.,5.,500)\n",
    "target = tf.constant(1.)\n",
    "targets = tf.fill([500,],1.)\n",
    "\n",
    "hinge_y_vals = tf.maximum(0., 1. -tf.multiply(target, x_vals))\n",
    "hinge_y_out = sess.run(hinge_y_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with Batch and Stochastic Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess=tf.Session()\n",
    "batch_size = 20\n",
    "x_vals = np.random.normal(1,0.1,100)\n",
    "y_vals = np.repeat(10.,100)\n",
    "x_data = tf.placeholder(shape=[None,None],dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None,None],dtype=tf.float32)\n",
    "A = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "my_output=tf.matmul(x_data,A)\n",
    "loss=tf.reduce_mean(tf.square(my_output - y_target))\n",
    "my_opt=tf.train.GradientDescentOptimizer(0.02)\n",
    "train_step=my_opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "Step #5A=[[ 2.50293779]]\n",
      "Loss=54.3462\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "Step #10A=[[ 3.88979983]]\n",
      "Loss=36.7599\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "Step #15A=[[ 5.01592159]]\n",
      "Loss=25.4127\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "Step #20A=[[ 5.92275238]]\n",
      "Loss=16.2747\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "Step #25A=[[ 6.64863253]]\n",
      "Loss=11.034\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "Step #30A=[[ 7.24307394]]\n",
      "Loss=8.01118\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "Step #35A=[[ 7.72087002]]\n",
      "Loss=5.39452\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "Step #40A=[[ 8.10711193]]\n",
      "Loss=2.69858\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "Step #45A=[[ 8.41249371]]\n",
      "Loss=2.57126\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "Step #50A=[[ 8.66823959]]\n",
      "Loss=2.55763\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "Step #55A=[[ 8.85830307]]\n",
      "Loss=1.25827\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "Step #60A=[[ 9.01735973]]\n",
      "Loss=1.53868\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "Step #65A=[[ 9.17091751]]\n",
      "Loss=0.93847\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "Step #70A=[[ 9.27029133]]\n",
      "Loss=0.858027\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "Step #75A=[[ 9.3754797]]\n",
      "Loss=1.2338\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "Step #80A=[[ 9.47189808]]\n",
      "Loss=0.695718\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "Step #85A=[[ 9.5354681]]\n",
      "Loss=0.659742\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "Step #90A=[[ 9.54354954]]\n",
      "Loss=0.577217\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "Step #95A=[[ 9.57517624]]\n",
      "Loss=1.1263\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Step #100A=[[ 9.6082716]]\n",
      "Loss=0.356119\n"
     ]
    }
   ],
   "source": [
    "loss_batch=[]\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess.run(init_op)\n",
    "for i in range(100):\n",
    "    rand_index=np.random.choice(100,size=batch_size)\n",
    "    rand_x=np.transpose([x_vals[rand_index]])\n",
    "    rand_y=np.transpose([y_vals[rand_index]])\n",
    "    print i\n",
    "    sess.run(train_step,feed_dict={x_data:rand_x,y_target:rand_y})\n",
    "    if (i+1)%5==0:\n",
    "        print('Step #' + str(i+1) + 'A=' +str(sess.run(A)))\n",
    "        temp_loss=sess.run(loss,feed_dict={x_data:rand_x,y_target:rand_y})\n",
    "        print('Loss='+str(temp_loss))\n",
    "        loss_batch.append(temp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0183431862056993]]\n",
      "[[1.0524616522008556]]\n",
      "[[1.0001382935926946]]\n",
      "[[1.0793012200456036]]\n",
      "[[0.90852554653632822]]\n",
      "Step #5 A = [[ 9.65662956]]\n",
      "Loss = 1.50481\n",
      "[[1.0564614751531733]]\n",
      "[[0.98640875176092624]]\n",
      "[[0.99267128770639568]]\n",
      "[[1.0540009835531303]]\n",
      "[[0.86013427065879444]]\n",
      "Step #10 A = [[ 9.73225117]]\n",
      "Loss = 2.6535\n",
      "[[1.0984629555397616]]\n",
      "[[0.75460337773026198]]\n",
      "[[0.95236217997661521]]\n",
      "[[0.85558801387100114]]\n",
      "[[1.0349342196653979]]\n",
      "Step #15 A = [[ 9.85519314]]\n",
      "Loss = 0.0397908\n",
      "[[1.0349342196653979]]\n",
      "[[1.0204720639609961]]\n",
      "[[1.0261441635963962]]\n",
      "[[1.0189237120101693]]\n",
      "[[1.045477620860608]]\n",
      "Step #20 A = [[ 9.82764626]]\n",
      "Loss = 0.0753968\n",
      "[[1.0095101731062812]]\n",
      "[[1.1531473821066234]]\n",
      "[[1.1458080297156585]]\n",
      "[[1.1454222853877585]]\n",
      "[[1.0204720639609961]]\n",
      "Step #25 A = [[ 9.6685257]]\n",
      "Loss = 0.017833\n",
      "[[0.92455278030407739]]\n",
      "[[1.0870876772971469]]\n",
      "[[0.96788457138815709]]\n",
      "[[1.0467977968501772]]\n",
      "[[1.143349232514929]]\n",
      "Step #30 A = [[ 9.65126133]]\n",
      "Loss = 1.07073\n",
      "[[1.0453782812963319]]\n",
      "[[0.92697820478036574]]\n",
      "[[0.96227759068412932]]\n",
      "[[0.99155960908691831]]\n",
      "[[1.0927677558468354]]\n",
      "Step #35 A = [[ 9.69995308]]\n",
      "Loss = 0.359754\n",
      "[[0.96062668554832353]]\n",
      "[[1.0026546920358212]]\n",
      "[[0.87990294304531924]]\n",
      "[[1.0630408673943028]]\n",
      "[[0.96227759068412932]]\n",
      "Step #40 A = [[ 9.7924509]]\n",
      "Loss = 0.332865\n",
      "[[1.0540009835531303]]\n",
      "[[1.0984629555397616]]\n",
      "[[1.0189237120101693]]\n",
      "[[1.0261441635963962]]\n",
      "[[1.0630616688786738]]\n",
      "Step #45 A = [[ 9.7335043]]\n",
      "Loss = 0.120628\n",
      "[[1.0611903611662861]]\n",
      "[[0.9581116306685783]]\n",
      "[[0.98733376361337077]]\n",
      "[[1.0927677558468354]]\n",
      "[[0.94594701965829453]]\n",
      "Step #50 A = [[ 9.76173115]]\n",
      "Loss = 0.586633\n",
      "[[1.0540009835531303]]\n",
      "[[1.216042085094686]]\n",
      "[[1.0026546920358212]]\n",
      "[[1.0988488125565969]]\n",
      "[[0.75460337773026198]]\n",
      "Step #55 A = [[ 9.72648621]]\n",
      "Loss = 7.07752\n",
      "[[0.98041959994235495]]\n",
      "[[1.1458080297156585]]\n",
      "[[1.1183983979212888]]\n",
      "[[1.2021488809608607]]\n",
      "[[0.92697820478036574]]\n",
      "Step #60 A = [[ 9.61818409]]\n",
      "Loss = 1.17539\n",
      "[[0.94594701965829453]]\n",
      "[[1.0575233541556117]]\n",
      "[[1.0540009835531303]]\n",
      "[[0.95236217997661521]]\n",
      "[[1.1411821622887142]]\n",
      "Step #65 A = [[ 9.62078094]]\n",
      "Loss = 0.958566\n",
      "[[1.0453782812963319]]\n",
      "[[0.98733376361337077]]\n",
      "[[1.021406525278872]]\n",
      "[[1.0793012200456036]]\n",
      "[[0.98733376361337077]]\n",
      "Step #70 A = [[ 9.64648819]]\n",
      "Loss = 0.226287\n",
      "[[1.0522256714517597]]\n",
      "[[0.96788457138815709]]\n",
      "[[0.94594701965829453]]\n",
      "[[1.0198435675544335]]\n",
      "[[0.86013427065879444]]\n",
      "Step #75 A = [[ 9.75984478]]\n",
      "Loss = 2.57674\n",
      "[[0.94805595410503773]]\n",
      "[[0.99525592805126983]]\n",
      "[[0.9581116306685783]]\n",
      "[[1.2021488809608607]]\n",
      "[[1.0183431862056993]]\n",
      "Step #80 A = [[ 9.73852253]]\n",
      "Loss = 0.00686278\n",
      "[[1.0095101731062812]]\n",
      "[[1.045477620860608]]\n",
      "[[1.2021488809608607]]\n",
      "[[1.0585870008371601]]\n",
      "[[0.94713788015374445]]\n",
      "Step #85 A = [[ 9.67879391]]\n",
      "Loss = 0.693635\n",
      "[[1.0026546920358212]]\n",
      "[[0.99820192708236288]]\n",
      "[[0.96485280651653527]]\n",
      "[[1.1332605165420522]]\n",
      "[[1.0540009835531303]]\n",
      "Step #90 A = [[ 9.67321301]]\n",
      "Loss = 0.0382499\n",
      "[[0.94743280020449472]]\n",
      "[[0.83509696225627028]]\n",
      "[[1.0575233541556117]]\n",
      "[[0.8870243183094122]]\n",
      "[[1.1183626625072314]]\n",
      "Step #95 A = [[ 9.75899792]]\n",
      "Loss = 0.835577\n",
      "[[1.0590891622891503]]\n",
      "[[0.9581116306685783]]\n",
      "[[0.96645221885681609]]\n",
      "[[0.97057198527913502]]\n",
      "[[1.0522256714517597]]\n",
      "Step #100 A = [[ 9.79741669]]\n",
      "Loss = 0.0955388\n"
     ]
    }
   ],
   "source": [
    "loss_stochastic = []\n",
    "for i in range(100):\n",
    "    rand_index = np.random.choice(100)\n",
    "    rand_x = [[x_vals[rand_index]]]\n",
    "    rand_y = [[y_vals[rand_index]]]\n",
    "    print rand_x\n",
    "    sess.run(train_step, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "    if (i+1)%5==0:\n",
    "            print('Step #' + str(i+1) + ' A = ' + str(sess.run(A)))\n",
    "            temp_loss = sess.run(loss, feed_dict={x_data: rand_x, y_target: rand_y})\n",
    "            print('Loss = ' + str(temp_loss))\n",
    "            loss_stochastic.append(temp_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xd4VNX28PHvTsFQQzEgECCIkIAhCQZp6iWCICI2BAVF\nwAIiNrygoP6wF96LgqIooqjYr2ChiJcLXLBgo5cQpJdQQw8lpK33jz0pQELq5GRm1ud5zjMzp806\nk8k6e/bZZ28jIiillPJ8fk4HoJRSqnRoQldKKS+hCV0ppbyEJnSllPISmtCVUspLaEJXSikvoQld\nKaW8hCZ0pZTyEprQlVLKSwSU5ZtdeOGFEhYWVpZvqZRSHm/ZsmUHRCSkoPXKNKGHhYWxdOnSsnxL\npZTyeMaY7YVZT6tclFLKS2hCV0opL6EJXSmlvIQmdKWU8hJlelFUKW+UlpZGYmIiKSkpToeiPFhQ\nUBChoaEEBgYWex+a0JUqocTERKpWrUpYWBjGGKfDUR5IRDh48CCJiYk0bty42PvRKhelSiglJYVa\ntWppMlfFZoyhVq1aJf6VpwldqVKgyVyVVGl8hzwjoX/7LURHw6lTTkeilFLllmck9AsugNWr4Y8/\nnI5EKY8wbdo0WrVqRUxMDBEREdxxxx0APPfcc6SmppZo33FxccyePbs0wmTbtm1Mnjz5jHndu3dn\n8+bN593uueeeY8SIEaUSgzfxjIR+5ZXg5weLFjkdiVLl3p49exg6dCgzZ85k5cqVJCQk8PjjjwPw\n/PPPlzihl6a8EvqcOXNo0qSJQxF5Ns9o5RIcDJddBgsXwvPPOx2NUvkaNgxWrnTPvmNi4I03Cl5v\n7969BAYGUqtWLcDWzbZq1YoHH3wQgA4dOuDn58eiRYs4ffo0Q4YMYfPmzYgIjz/+OP379wcgISGB\nRx99lL179yIijBgxggEDBgDw008/MWbMGHbv3s1tt93GmDFjAHj99df56quvSE9PJygoiHfffZeY\nmBhOnjzJgAEDiI+PJzAwkPDwcL7++msefPBBtm7dSkxMDJdccgnTp08nLCyM2bNnExkZya5du3jk\nkUfYuHEjAH379uXJJ5/M99iPHz/Oww8/zJIlSwDo378/TzzxBGBPZl9++SVBQUEYY1i4cCEVKlTI\nMy5P5RkJHSAuDiZMgJMnoVIlp6NRqtyKjo6mTZs2NGzYkLi4OK688kruuusuJk6cyDvvvMNvv/1G\nlSpVALj99tuJjIzku+++Y8+ePcTGxnLZZZcRERHBTTfdxMsvv0zv3r0BOHjwYPZ77Nixg59//pnk\n5GSaNGnCvffeS9OmTenfvz/Dhw8HYP78+QwZMoQ//viDuXPncuzYMdatWwfA4cOHAZg4cSIjRozI\nt9O+fv360b17d7755hsADhw4cN5jf/HFF8nMzGTNmjUkJyfTvn17WrZsSdu2bRk/fjx79uyhYsWK\nJCcnU7FiRWbNmpVnXJ7KcxJ6t26waRMcPqwJXZVbhSlBu5ufnx/ff/89a9eu5aeffuL7779n7Nix\nrFmz5px158+fz+uvvw5A3bp16d69OwsXLsQYQ3p6enYyB7JL/AC9e/fGz8+P4OBgmjdvzubNm2na\ntCnLli3jlVde4dChQ/j5+bFhwwbAnmQSEhJ48MEHiYuL4/rrry/wOI4fP85vv/3GvHnzsuddeOGF\n591m/vz5vPnmmxhjqFatGn379mX+/Pl07dqVSy65hP79+9O1a1d69OhB1apVixVXeeYZdegAnTvD\nd99B/fpOR6KUR4iMjOTBBx9k3rx5BAcHs6gUr0EFBQVlP/f39yc9PZ3U1FR69erFG2+8wdq1a/nP\nf/7D6dOnAbj44ouJj4+nS5cuzJ8/n+jo6DK9s9bf358//viDhx56iMTERGJjY1m9erXjcZU2z0no\nWQ4dcjoCpcq1Xbt28fvvv2e/TkxMJCkpicaNG1O1alWOHj2aveyaa67h/fffB2zd+5w5c+jUqRPh\n4eEEBAQwbdq07HVzV7nkJSUlhfT0dBo0aADAO++8c0YM/v7+3HzzzYwfP56kpCQOHTpEtWrVzogn\ntypVqtChQwfGjx+fPa+gKpdrrrmGKVOmICIkJyfz1Vdf0aVLF5KTk0lKSqJjx448//zzREZGsnbt\n2nzj8lSeldDHjIG6dW09ulIqT+np6Tz77LOEh4cTExND9+7deemll2jVqhXDhw+nU6dOxMTEcOTI\nESZMmMCqVauIioqiS5cujBkzhksvvZSAgABmzJjBpEmTaNmyJdHR0cyZM+e871utWjVeeOEFLr/8\ncmJjY6lcuXL2sjVr1tC+ffvs+v0nn3ySevXqERUVRXh4OJGRkfTq1eucfX722WcsXryYyMhIoqOj\nmTJlSvay9957j9DQ0OzpvffeY/To0YgILVu2pH379tx1111069aNo0ePcvPNNxMVFUVkZCQXXXQR\nPXv2zDcuT2VEpMzerHXr1lKiEYvmzIHrr4cFC6BTp9ILTKkSSEhIoHnz5k6HobxAft8lY8wyEWld\n0PaeVULX9uhKKZUvz0ro1apBbKwmdKWUykOhEroxZpsxZo0xZqUxZqlrXk1jzDxjzEbXYw33huoS\nFwd//qn16EopdZailNCvFpGYXPU4o4AFItIUWOB67X633w6vvQaZmWXydkop5SlKcmPRTUCc6/lU\nYBEwsoTxFCw21k5KKaXOUNgSugDzjTHLjDGDXfPqiMge1/O9QJ1Sjy4/e/fCf/9bZm+nlFKeoLAJ\n/UoRiQGuAx40xvwj90KxbR/zbP9ojBlsjFlqjFmalJRUsmizjB8PN9yg9ehK5SEsLIyIiIjsrnMH\nDRpEWlpagdt9/PHH2bfqn8+iRYto3brAFnQADBw4kLfffrtQ67rL7t27ufrqq936Hhs2bODqq68m\nIiKCyMhI7r77bk7lGr/hjz/+IDo6mmbNmtG1a1f279/vljgKldBFZJfrcT/wHdAG2GeMqQvgeswz\nQhGZLCKtRaR1SEhI6UQdFwepqdo/ulL5mD59OitXriQ+Pp74+Hi+/fbbArcpbEL3NPXq1WPhwoVu\nfY8KFSowbtw41q9fz+rVqzl58iSvvfYaAJmZmfTr14+JEyeyYcMG/vGPfzBqlHsuORaY0I0xlY0x\nVbOeA12BtcBMYIBrtQHADLdEmJcrrgB/f22+qFQBUlJSSElJoUYN2whtwYIFtG/fnlatWtGyZUu+\n+uorAD766COWLl3KI488QkxMDPPnzwfg1Vdfzb5TtEOHDmS6GiOkp6dz//33ExUVld3BVVHs27eP\nW265haioKFq2bMknn3wC2OQ3dOhQIiIiiI6O5oorrgBg//79XHPNNbRs2ZKWLVvy2GOPnbPP/Lbd\ntm1bdqdec+bMISYmJnuqUKECM2bY1DV16lTatm1LbGwsnTp14u+//y708YSFhdGqVSvAdo7Wpk0b\ntm/fDsCyZcsICgriyiuvBGDIkCHu66JXRM47ARcDq1xTPPC0a34tbOuWjcB8oGZB+4qNjZVS06aN\nyFVXld7+lCqmdevWnTmjY8dzp7FjS295ARo1aiTh4eESHR0tVapUkZ49e2YvO3TokKSnp4uIyN69\ne6V+/fpy6NAh19t2lFmzZmWv+/HHH0u7du3k2LFjIiJy4MABERFZuHChBAQEyPLly0VE5KWXXpI7\n7rgjz1gGDBggb7311jnzb7vtNvm///s/ERHZvXu31K1bV9asWSPLly+XiIgIycjIyI5XRGTcuHEy\nePDgM47jbPltu3XrVqlVq9Y560+ePFnat28vp06dkp9//lm6d+8uKSkpIiIyZ84c6dChg4iIxMfH\nS3R0dJ7TiBEjztnvyZMnpUWLFjJjxgwREZk+fbp07979jHUqVqwoBw8ePGfbc75LLsBSKSC/ikjB\nrVxEZAsQncf8g0DnUjqvFF1cnO2rVPtHV+oc06dPJzIykpSUFG699VbeeOMNhg0bRlJSEvfccw8b\nN24kICCAQ4cO8ffff9OuXbtz9jF79mweeOABqlatCpzZfW54eHh2ibRdu3bMmjWrSPHl121v//79\nSUtL495776VTp0706NEj+z3Gjx/P448/TseOHbn22mvP2efFF1+c57Z5mTt3LuPGjeOXX34hKCiI\nWbNmsWrVKtq2bQvYgm5W3+gtWrRgZSFHLUlPT6dPnz506tSJG2+8sUifSWnwnP7Qz/bAA9CvH+Tq\nxlOpcqGgqsCSLi+CoKAgevTowezZsxk2bBgPPPAAN954I99++y3GGJo1a1as7mLz6j63NAQHBxMf\nH8+iRYuYP38+I0eOZPny5bRv354VK1Ywb948Pv30U8aMGcOvv/5aqG3PtmrVKoYMGcLcuXOzq2JE\nhHvuuYcXXnjhnPXXrVuXPSbr2bp06cLYsWMByMjI4M4776RGjRpMmDAhe52GDRtmV7+A7THSz8+P\nmjVrFv0DKoBn3fqfW1gYtGxp+3ZRSuUpMzOTn376iWbNmgFw5MgRwsLCMMYwb948Nm3alL3u2V3Z\n9ujRg3fffZfk5GSg4O5ziyK/bnuTkpI4efIk1157LWPGjCE4OJgtW7awdetWqlWrRp8+fRg3bhzL\nli0jMzOTXbt2ERERAZDvtrnt2rWLW2+9lc8++yz7MwG44YYb+OSTT0hMTARscl62bBmQU0LPa8pK\n5pmZmQwcOBB/f3+mTJmCMSZ737GxsZw6dSr7BDRp0qQzBg4pTZ5bQgfbFn35cnDTFWOlPFWvXr0I\nCgoiNTWVyMhInnnmGQDGjBnD0KFDefbZZ7n88suJiorK3mbw4MEMHz6csWPH8tprr9G/f3927dpF\nu3btCAwMpEqVKvz8889FjmX06NHZY44CTJ48mQkTJmRfVBWR7G57ly9fzqBBg0hPTyc9PZ3rrruO\ndu3aMXXqVMaNG4e/vz+ZmZlMmjQJPz8/du/eTUCATWM7d+7Mc9sdO3Zkv/cHH3xAUlJS9viqAOPH\nj+fqq6/m5Zdf5sYbbyQjI4PU1FR69+5NbCFvYvzxxx/57LPPiIyMzN7miiuuYOLEifj5+fHpp59y\n//33k5KSQlhYGJ999lmRP8fC8Kzuc882cqRtk374MOTqe1mpsqTd5zpn3Lhx1K5dm379+jkdSqnw\nre5zzxYXB2lpkGt0FqWU7/jnP//pNcm8NHh2Qtf26Eoplc2zE7r2j66UUtk8O6GDrXbZuhVKqdmU\nUsVRlteilHcqje+Q5yf0Z5+FnTshwLMb7CjPFRQUxMGDBzWpq2ITEQ4ePHhG+/7i8PwsqHeJKoeF\nhoaSmJhIqfUmqnxSUFAQoaGhJdqH5yd0gH/9C1atgs8/dzoS5YMCAwNp3Lix02Eo5QVVLmDboU+b\nBidOOB2JUko5xjsSurZHV0opL0no2h5dKaW8JKFXqQKXX64JXSnl07wjoQPcfDM0agTadEwp5aO8\no5UL2I66lFLKh3lPCT2LtnRRSvko70rovXtD165OR6GUUo7wroR+ySXw119aSldK+STvSuhxcbaT\nrt9+czoSpZQqc96V0LU9ulLKh3lXQtf26EopH+Y9zRazPPIIuEYpV0opX+J9Cb1vX6cjUEopR3hX\nlUuWnTthxQqno1BKqTLlfSV0gNtvt4/a2kUp5UO8s4QeFwdLlsDx405HopRSZabQCd0Y42+MWWGM\nme16XdMYM88Ys9H1WMN9YRaRtkdXSvmgopTQHwUScr0eBSwQkabAAtfr8qFDBztotDZfVEr5kEIl\ndGNMKHA98EGu2TcBU13PpwI3l25oJaDt0ZVSPqiwF0XfAJ4AquaaV0dE9rie7wXq5LWhMWYwMBig\nYcOGxQyzGMaPh+Dgsns/pZRyWIEldGNMD2C/iCzLbx0RESDPkSVEZLKItBaR1iEhIcWPtKjatoWI\niLJ7P6WUclhhSuhXADcaY7oDQUA1Y8xnwD5jTF0R2WOMqQvsd2egxfLllxAYCL16OR2JUkq5XYEl\ndBF5UkRCRSQM6AP8T0T6ATOBAa7VBgAz3BZlcb39Nrz+utNRKKVUmShJO/QxQBdjzEbgGtfr8kXb\noyulfEiRErqILBKRHq7nB0Wks4g0FZFrROSQe0Isgbg4yMiAxYudjkQppdzOO+8UzaLt0ZVSPsS7\nE3rlytCmDaxa5XQkSinldt7ZOVdus2dD9epOR6GUUm7n/Qm9RvnpYkYppdzJu6tcAERg8GAYN87p\nSJRSyq28P6EbA/Hx8PXXTkeilFJu5f0JHaBrV9sefedOpyNRSim38Y2E3r8/ZGbCxx87HYlSSrmN\nbyT0xo2hc2f48EOb2JVSygv5RkIHGDoUOnaE5GSnI1FKKbfw/maLWXr2tJNSSnkp3ymhZ1m+HA4f\ndjoKpZQqdb6V0BMSIDYWPv3U6UiUUqrU+VZCb97cJvQpU+wNR0op5UV8K6ED3HcfrF4Ny/IdUU8p\npTyS7yX0vn2hYkX44AOnI1FKqVLlewk9OBh694Zvv4X0dKejUUqpUuN7CR3gpZfsBdIA32m1qZTy\nfr6Z0Ro0cDoCpZQqdb5ZQgc7ilGHDrBhg9ORKKVUqfDdhF67Nvz1l+3fRSmlvIDvJvS6deH6620P\njGlpTkejlFIl5rsJHWyb9H37YM4cpyNRSqkS8+2Eft11tqSubdKVUl7AN1u5ZAkIgKeegtRUpyNR\nSqkS8+2EDvDQQ05HoJRSpcK3q1yynDoF06bpaEZKKY9WYEI3xgQZY/4yxqwyxsQbY553za9pjJln\njNnoeqzh/nDd5Jtv4Lbb4OefnY5EKaWKrTAl9NNAJxGJBmKAbsaYdsAoYIGINAUWuF57pp49bR8v\nU6Y4HYlSShVbgQldrOOul4GuSYCbgKmu+VOBm90SYVmoVAnuuAOmT4cjR5yORimliqVQdejGGH9j\nzEpgPzBPRP4E6ojIHtcqe4E6boqxbNx3H6SkwBdfOB2JUkoVS6ESuohkiEgMEAq0McZEnrVcsKX2\ncxhjBhtjlhpjliYlJZU4YLe57DKIiYG5c52ORCmliqVIrVxE5AiwEOgG7DPG1AVwPe7PZ5vJItJa\nRFqHhISUNF73+uEH+O47p6NQSqliKUwrlxBjTHXX84pAF2A9MBMY4FptADDDXUGWmXr1wM9PxxtV\nSnmkwpTQ6wILjTGrgSXYOvTZwBigizFmI3CN67Xn++ILCA+3bdOVUsqDFHinqIisBlrlMf8g0Nkd\nQTnqootg40Y7RN2ddzodjVJKFZreKXq2uDi4+GJtk66U8jia0M/m5wf33AMLF8LmzU5Ho5RShaYJ\nPS8DB9rErqMZKaU8iPa2mJf69eHFF6FdO6cjUUqpQtOEnp+nnnI6AqWUKhKtcjmfTZvg00+djkIp\npQpFE/r5TJ5sL5Du3et0JEopVSBN6Odzzz2Qng6ffOJ0JEopVSBN6OcTEQFXXmnbpGt3AEqpck4T\nekHuvRc2bIDFi52ORCmlzksTekF694bq1eGvv5yORCmlzkubLRakcmXYsQOqVnU6EqWUOi8toRdG\nVjI/dMjZOJRS6jw0oRfWuHG20y4dc1QpVU5pQi+sTp3g6FF4+22nI1FKqTxpQi+smBjo0QPGj4fj\nx52ORimlzqEJvSieftrWo7/3ntORKKXUOTShF0W7drbqZcIEyMhwOhqllDqDNlssqrfftk0Z/f2d\njkQppc6gCb2omjfPeS4CxjgXi1JK5aJVLsVx+DB07QpTpzodiVJKZdOEXhzVq8OBA/DKK1qXrpQq\nNzShF4cxdkSjjRth+nSno1FKKUATevH17Gm71335ZcjMdDoapZTShF5sfn62lL5mDcye7XQ0Siml\nrVxKpG9f2LnTtk9XSimHaUIviYAAW0pXSqlyQKtcSsOCBfDII05HoZTycQUmdGNMA2PMQmPMOmNM\nvDHmUdf8msaYecaYja7HGu4Pt5xaswbeegt+/dXpSJRSPqwwJfR0YLiItADaAQ8aY1oAo4AFItIU\nWOB67ZsGDYKQENviRSmlHFJgQheRPSKy3PU8GUgA6gM3AVm3Sk4FbnZXkOVe5crw2GPwn//AsmVO\nR6OU8lFFqkM3xoQBrYA/gToisse1aC9QJ59tBhtjlhpjliYlJZUg1HJu6FAIDrZ3jyqllAMKndCN\nMVWAb4BhInIs9zIREUDy2k5EJotIaxFpHRISUqJgy7XgYBg9Glq3tp12KaVUGStUs0VjTCA2mX8u\nIt+6Zu8zxtQVkT3GmLrAfncF6TGGD3c6AqWUDytMKxcDTAESRGRcrkUzgQGu5wOAGaUfngfKyICv\nvoItW5yORCnlYwpT5XIFcBfQyRiz0jV1B8YAXYwxG4FrXK9VUhIMHAivvup0JEopH1NglYuI/Ark\nN4pD59INxwtcdBHcdx9MngzPPAMNGjgdkVLKR+idou7wxBP2wujYsU5HopTyIZrQ3aFhQ7jrLnj/\nfdi3z+lolFI+QhO6u4waBbVr20EwlFKqDGhvi+7SrJlt6eLv73QkSikfoSV0d/L3h9RUWLHC6UiU\nUj5AE7q7DR0KnTtDcrLTkSilvJwmdHe7/344fBjefdfpSJRSXk4Turtdfjl07WqbMCYmOh2NUsqL\naUIvC+PHw+nTcOONcOKE09EopbyUJvSy0KKF7d8lLQ0OHXI6GqWUl9Jmi2Wle3db9RIQYO8iNfn1\npqCUUsWjJfSyFBAAKSlw550wdWrB6yulVBFoQi9r/v62O4BBg3RQaaVUqdKEXtYCA2HaNAgLg1tu\n0X7TlVKlRhO6E2rWhNmz7WAYN9wAR486HZFSygtoQndKs2YwfTrs3g1r1jgdjVLKC2grFyd16gTb\nttkBppVSqoS0hO60rGQ+aZKdlFKqmDShlweZmfDDD/DQQzBvntPRKKU8lCb08sDPD774Apo3h969\nYf16pyNSSnkgTejlRdWqMGsWVKgAPXrAwYNOR6SU8jCa0MuTsDD4/nvbK+P06U5Ho5TyMNrKpbzp\n0AHi46FJE6cjUUp5GC2hl0dZyXzZMpg82dlYlFIeQxN6efbmmzBkiK1bV0qpAmhCL88mTYLYWLjj\nDli92ulolFLlnCb08qxSJZgxw9581K0bLFzodERKqXKswIRujPnQGLPfGLM217yaxph5xpiNrsca\n7g3Th9WrBz/+CFWqwDvvOB2NUqocK0wJ/WOg21nzRgELRKQpsMD1WrlLy5awcmXOBdKNG2HJEmdj\nUkqVOwUmdBH5GTh7IMybgKwhd6YCN5dyXOpslSpBDdcPoVGjoH17eO45O06pUkpR/Dr0OiKyx/V8\nL1CnlOJRhTFlir1Q+vzzNrEnJDgdkVKqHCjxRVEREUDyW26MGWyMWWqMWZqUlFTSt1MA1avDJ5/A\nN9/A9u3QqhXMnet0VEophxU3oe8zxtQFcD3uz29FEZksIq1FpHVISEgx307lqWdPWLsW+veHdu3s\nPMn33KqU8nLFTegzgQGu5wOAGaUTjiqyOnXsxdLgYEhNhbg4+OgjTexK+aDCNFv8EvgdCDfGJBpj\n7gXGAF2MMRuBa1yvldOOHrVd8d5zD9x0E+zb53RESqkyVGDnXCLSN59FnUs5FlVSISGwYAFMmABP\nPgmRkfZu01tvdToypVQZ0DtFvY2fHwwbBsuX2+54R42C06edjkopVQY0oXur5s3ht9/skHYXXADH\nj9s+1rVuXSmvpQndmwUG2lI62LbrvXtDp062ZYxSyutoQvcVDz1k69NXr4aYGPjnP+1FVKWU19CE\n7iv8/eH++2HDBrjvPnjjDXu3qSrQnj0wcSKkpzsdiVLnp0PQ+ZpatWxJfdAgm+QBDhyAHTvgssuc\nja0cysyEPn3g559h1y545RWnI1Iqf1pC91WxsbbqBWyWat0ahg6FQ2f3w+bbJkywyTwqCl59VXtY\nUOWbJnQFzzwDDz8M770HzZrZO08zMpyOynF//22b8/foAb//bpv133UX7N7tdGRK5U0TurKdfb35\nJqxYAZdeauvaH3vM6agclZ4OAwbYXosnT7aPX38NJ07YSw9an67KI03oKkdUFCxaBF98AQ88YOft\n3Qv78+17zWuNHQt//mkvhtata+c1b24HjfrpJ3jhBWfjUyovmtDVmYyBvn1t9gJbUm/WDN56y2eK\npWvWwLPP2mb7t99+5rIBA+z00kswf74z8SmVH03o6vyefRbatIFHHrGPf/7pdERulZpqeyOuUcOW\nxo05d52JEyEiAvr1sz9glCovNKGr84uIsE07vv7a9t7Yvj28/77TUbnNSy/lDN964YV5r1O5sv04\njh2DO+/U68eq/NCErgpmjK1/SEiA4cPhuuvs/CNHvKpvmKVLbQvO/v1t78PnExlpa6H+9z94+eWy\niU+pghgpw3/I1q1by9KlS8vs/ZQbiUDnzrZe/d13besYD5aSYu+rOnbMdnVTvXrB24jYZoxffml7\nLY6Lc3uYykcZY5aJSOuC1tMSuioeEdt+Lz7e3qA0cqRt0+ehRo+2P0CmTClcMgf7w2XSJGja1H4U\nPtgYSJUzmtBV8fj52T5h1q+3dRT/+he0aAHLljkdWZEtXgyvv26b3197bdG2rVLF1qcfPmxL65mZ\n7olRqcLQhK5KJiTEFmt/+QWaNMnprtdDMtuJE7YZYliYbXteHFFR9r6s//4XxuhgjMpBmtBV6bjy\nSnuFsFYt2+yjY0d7hTE11enIzmvkSNi82Y6rXbVq8fczaJDtxGv0aHtuU8oJmtBV6Tt+HGrXhqef\nhuhoWLjQ6YjytGCBbVM+bJg9/5SEMbYrnIsvtvdlHThQOjEqVRRe38rlyBF7N3t6OtxyS06PsaoM\nzJljB9bYuhW6dYMZM6BCBZg9G/76C4KC7PB4WY8DB0JAgL3Qmph45rIKFWwdvTG2PfyRIzl3/Rhj\npyZN7OOBA5CcnDMfbGV3rVrZoR09aqtKKla0XdhUrFg6h7xiBbRrZxsAzZ5tLzV4OhHbCWeuj0+V\nscK2ckFEymyKjY0VdztxQuS//xUZOVLk8stF/PxE7FdSJDZW5Pff3R6Cyu3ECZGnnxYJCxNJS7Pz\nHn4454+Se0pNtcuHDi395caIJCXZ5UlJcu/dGeLnJ/LHH6V/yBMn2rf8f/+v9Pdd1v73P5E2bezx\n3HKLyJbNFH9sAAANmUlEQVQtTkfkm4ClUogc6/El9LQ0WLLEVt8uWGDHRU5NtQW9tm1tSalzZzs4\nwYgRtuvTu++2fVvXqVOqoaiiELF/vJQUOH3aTvXr2xL19u32D3b6dM7y1FTo1csWeZcutSMvZe0n\n6zt8xx12+R9/2NY3WfNFbL3+oEEA7GvTA5YsIbHldcQ+0wO6doVq1Ur10G67Db77zval3qFDqe26\nzKxYYbsOnjsXGjSwN1p9+KH9GB9/HEaNsnfMqrLhtSX0jAyRlStFxo0Tuf56kSpVcgphMTEiw4eL\nzJkjkpx87rbHjok88YRIYKBIcLDIm2/mFBqVbzhwQOTe6tNldvAdklmjhv3iBASI3Htvqb7PkSMi\nF18s0qCBfU9PsXGjSJ8+9mOpWVPktddETp2yyxITRe680y4LDRX58kuRzExn4/UVFLKE7hEJfetW\nkffeE7ntNpGQkJwE3rSpyJAhItOm5fyaLoz160W6drX7iIwUWbiwWGEpD9S3r83fK1aIPZv/8out\nnxs/3q6Qmmrr5oYNE5k3T+T06aK9QWqqyO7dIuvWyboPFssN/j/I2FafS+bOxJzl5bAUsWePyAMP\n2M+mUiVbS3bkSN7r/vqryGWX2f+fq64SWb68bGP1RV6V0AcNspHWqydy110iH30ksmNHsXaVLTNT\n5LvvRBo1svvu00dk586S7VOVb9Om2b/1Cy+cZ6Xdu0Wuu07kggvsylWrivTsKbJ4sV2+dq0tRfTp\nI9Ktm0jbtiLh4fbCjYjIzJlyTv09yDf9v5OTJ0UyZ86yWfOSS0SuvdbW97/+es6Xr4yLvEeO2ORd\nqZIN64EH7EcgmZn2J+2mTSK//ZZzEsrIEBGR9HSR99+3BSxjRO6/v2iFKlU0hU3oHlGHvnGjrbsL\nD8+7O9OSOHnS3uQ4Zoytdx892jZju+CC0n0fJxw8CL/+attF79hhb1Fv0cJ2dR4RYUfh8RX79tkO\ntcLC7HWWwMACNjhxwl6YmT3bTpMnw/XX20rxXr1s/wA1atjH6tXhn/+0F2127oQffsheJsHVeXh0\ndT6c34BTVCLKby0DAz/nEr/NNJYtNEzbTLWMIzxx1e/sadSOTrs/49Y/n+BIrYs5XrsJp+o1IbVB\nE07GdadJ6xo0rJiEX9I+ewCBgfZLGxhob/AKCLDNuTIz7by8/lkOHYKtW0lN3M+CL/fz+8wkqpza\nT8Kto3l6TFUu+c/b9g6r/fvt9Yssu3fbkT6ee87eRRUWBo0acfqiRvyY0IgBi+/Hr2plXhydyv0P\nBRJYoZT/UcvKpk32+sy2bXbavt22tJo61S7PupAQGWmnkty8UASFrUMvUUI3xnQD3gT8gQ9E5Lz3\nyZXnzrm2bLH/kzNm2PEcJkwo+m3gTtu50ybvrCk+3s6vUAFCQ+13M6urV2OgUSOb3LOSfNZUo4Zz\nx+AOItCzJ/z4Iyxfbo+3yDvIzCx2m9fjx20HXgcP2taUycl2XtZzc/gQ+09W4fCJClx66Bd6Hf+I\nsIzNNGEzoewCoDnrWE9zRlYYx5jU4ee8R2Z8An4tImD8ePtFBhtvVsJftgyaNSPjlTH4P/3kmdtW\nuAC/+LVwySXw/fd2Cgmx9xJkTR072hLAjz/aE1xWstu+HY4fJ2H5KR4dGUT3ecMYbD4gs2Ejqlwa\nZr9kjRrZmAID7QXtnTvtxeusyd/fNmsF26HOvn3Zy06d9mPHLn/+rt6WBg2gWeVdVM5MzjmhZU1Z\nfR2np+fsNy+bN9sL5rkTdlqavYINNg7XSOAZARU4Uq0R6yvGMLTW1zRsCO8uiSV03/Kc/YWF2RP9\n22/b19u32xNfhQpF+o4UxO0J3RjjD2wAugCJwBKgr4isy2+b8pzQs/z4Izz6qP1VcPPNMG4cNG7s\ndFTnErGDGOdO4Nu22WVVq9qWFVddZac2bWwh4/RpWwBJSIB16+xjQoLdT+7C2EUXnZvoGze2ucHP\nz54M8no837KAAPfdA5CaCnv22IYxuafExJzHrVttwXPECPfEUNrS023SP550ipT129hT+RISNgWy\n/9cNyMpV7N2ZxvEjaQSQTiBpzKzYh3otqnNDnb+4OmMedWqlU6dGGsGV0jDpacioJ/l+cQjvj/ib\nwC3rubB5be57qjbtb6pt2+gX96eviL0noEYNRODP0bNZ99YCahzbRnTwdhqZ7fifPmV/8Rhj7zXI\nKu1m7SIwkD3bUlm/Huo9NZCIP89cfpoKBHEagI8YyEDOXJ4ZEMim+FQaN4bAQa79+/nlJPtKlexJ\nAuztvP/+t31+wQVkNGjE0dpN+feds1i12pD22xK2bUpn3akw9lEHjB9Nm9pz3fbtsGF9JvUzttOS\nNbRkLe2qrCG9Tn2W3PYal14KvR+rT+Dh/ZiICFuCb9kS/vEPeyd1CZRFQm8PPCci17pePwkgIq/m\nt40nJHSwiW/8eHjxRVswGznSTmfffJJVQZqZWfAkklNg8vc/83lh/pfS02HVqjMTeFKSXRYSYr8z\nWQk8Ksruu7AyMuzJICvB5074x44Vfj8FCQqyuaNqVft49vPzLfP3t0k7K0nnnvLq5fCCC2wryKyp\nVSvblbs33Vh2+LD9O8XHn/m4e3fOOpUq2RNyZqZtihgebntkuOWW0q++zJKSYgtCL79sv1tPPXqC\n4c9UJiAAtv+6k52rDrFtSybbt9ppx3Zh0ck2AISznsZBewlrmEmjBpk0DM2kQahQ4YZr2bkTji/4\nk1PxW0jak8bBPWmcPpGGQZjEA/j7w6DaM7iy6kpq10gjJDiNWtXSqFEDKr47ji1bYPvMVWyJP8Vv\nu8P45e/abNmWU5KvXt3e2BwVZafoaNsrdO6qybQ0W9iLjz9z2rABMjKEvnxJFGtoW2kNl8oaap/a\nwZaOd3PirQ8JDy9+wb0sEnovoJuI3Od6fRfQVkQeym8bT0noWRITbYnu3/+2J3o/v3OTdGkwJu9E\nn/v5kSO2xAa2tJyVvK+6ylYRueOfU8Qm0XXrbB181jHn9Xi+ZeJqcn78eM6UVe1w9vPjx+0J9Xxq\n1TozWYeGnvm6fn2oWdN9Cau8O3zYnoyzks26dfbm2aFDc27GLQu7dtmC0Oef25PzyZNnju4UGmqv\n5Zw91atX+L/dwYM2wW7YYKe//7aPGzfCqVM56xmT8//q52dPbLkTd1SUjae435nUVPu+Zyf6/RuP\nckHmSfZSl++/L3jglPyUm4RujBkMDAZo2LBh7Pbt24v1fk5atMjexZ67auHsyd8//2VZ1XkZGXZK\nTy/4+dmvK1XKqUYJDXX043C71FT7Cz13sk9Ls1WT9erZkr7yHIsX287P6tWzCTs83BZC3Hk9MTPT\nnlCyEn1ioq02iYqyVYml1dVDQU6ftieZ+Hh7g2Pt2sXbj1a5KKWUlyiLEYuWAE2NMY2NMRWAPsDM\nEuxPKaVUCRS7Nk1E0o0xDwFzsc0WPxSR+FKLTCmlVJGU6PKIiMwB5pRSLEoppUrAC3prVkopBZrQ\nlVLKa2hCV0opL6EJXSmlvIQmdKWU8hJl2n2uMSYJKO6tohcCvjyWuh6/Hr8ev+9qJCIhBa1Upgm9\nJIwxSwtzp5S30uPX49fj993jLyytclFKKS+hCV0ppbyEJyX0yU4H4DA9ft+mx68K5DF16Eoppc7P\nk0roSimlzsMjEroxppsx5m9jzCZjzCin43E3Y0wDY8xCY8w6Y0y8MeZR1/yaxph5xpiNrkcvG845\nhzHG3xizwhgz2/XaZ44dwBhT3Rgz3Riz3hiTYIxp70ufgTHmMdd3f60x5ktjTJAvHX9xlfuE7hqM\neiJwHdAC6GuMKeq47Z4mHRguIi2AdsCDrmMeBSwQkabAAtdrb/UokJDrtS8dO8CbwH9EJAKIxn4W\nPvEZGGPqA48ArUUkEts9dx985PhLotwndKANsElEtohIKvAVUMyR+TyDiOwRkeWu58nYf+b62OPO\nGvJ8KnCzMxG6lzEmFLge+CDXbJ84dgBjTDDwD2AKgIikisgRfOgzwHbtXdEYEwBUAnbjW8dfLJ6Q\n0OsDO3O9TnTN8wnGmDCgFfAnUEdE9rgW7QXqOBSWu70BPAFk5prnK8cO0BhIAj5yVTt9YIypjI98\nBiKyC3gN2AHsAY6KyH/xkeMvCU9I6D7LGFMF+AYYJiLHci8T2zzJ65ooGWN6APtFZFl+63jrsecS\nAFwGvCsirYATnFW94M2fgatu/Cbsia0eUNkY0y/3Ot58/CXhCQl9F9Ag1+tQ1zyvZowJxCbzz0Xk\nW9fsfcaYuq7ldYH9TsXnRlcANxpjtmGr1zoZYz7DN449SyKQKCJ/ul5PxyZ4X/kMrgG2ikiSiKQB\n3wId8J3jLzZPSOg+Nxi1McZg608TRGRcrkUzgQGu5wOAGWUdm7uJyJMiEioiYdi/9f9EpB8+cOxZ\nRGQvsNMYE+6a1RlYh+98BjuAdsaYSq7/hc7Y60i+cvzF5hE3FhljumPrVbMGo37Z4ZDcyhhzJfAL\nsIaceuSnsPXoXwMNsb1W3iYihxwJsgwYY+KAESLSwxhTC9869hjsReEKwBbgbmwBzCc+A2PM88Dt\n2BZfK4D7gCr4yPEXl0ckdKWUUgXzhCoXpZRShaAJXSmlvIQmdKWU8hKa0JVSyktoQldKKS+hCV0p\npbyEJnSllPISmtCVUspL/H+x1KhrgxOCvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11c19c850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(0, 100, 5), loss_stochastic, 'b-', label='StochasticLoss')\n",
    "plt.plot(range(0, 100, 5), loss_batch, 'r--', label='Batch Loss,size=20')\n",
    "plt.legend(loc='upper right', prop={'size': 11})\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
